#!/usr/bin/env python3
"""
analyze_results.py - Analyze ivshmem performance test results

This script loads the CSV files generated by host_writer and produces:
- Latency analysis: histogram plots, time series, percentile charts
- Bandwidth analysis: performance by frame type, success rates, duration analysis
- Detailed statistics (p50, p90, p95, p99, min, max, mean, stddev)
- Comprehensive performance report with visualizations
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import sys
import os
from pathlib import Path


def load_latency_data(csv_path='latency_results.csv'):
    """Load latency data from CSV file"""
    if not os.path.exists(csv_path):
        print(f"Error: {csv_path} not found")
        print("Run the host_writer test first to generate data.")
        return None
    
    df = pd.read_csv(csv_path)
    print(f"Loaded {len(df)} latency measurements from {csv_path}")
    return df


def load_bandwidth_data(csv_path='bandwidth_results.csv'):
    """Load bandwidth data from CSV file"""
    if not os.path.exists(csv_path):
        print(f"Warning: {csv_path} not found")
        return None
    
    df = pd.read_csv(csv_path)
    print(f"Loaded bandwidth test results from {csv_path}")
    return df


def load_performance_data(csv_path='latency_performance.csv'):
    """Load performance counter data from CSV file"""
    if not os.path.exists(csv_path):
        print(f"Warning: {csv_path} not found")
        return None
    
    df = pd.read_csv(csv_path)
    print(f"Loaded {len(df)} performance counter measurements from {csv_path}")
    return df


def calculate_statistics(data, column_name, unit='ns'):
    """Calculate comprehensive statistics for a data series"""
    stats = {
        'count': len(data),
        'min': data.min(),
        'max': data.max(),
        'mean': data.mean(),
        'median': data.median(),
        'std': data.std(),
        'p50': data.quantile(0.50),
        'p90': data.quantile(0.90),
        'p95': data.quantile(0.95),
        'p99': data.quantile(0.99),
        'p999': data.quantile(0.999) if len(data) >= 1000 else None,
    }
    
    print(f"\n{'='*60}")
    print(f"Statistics for {column_name}")
    print(f"{'='*60}")
    print(f"Count:         {stats['count']:>12}")
    print(f"Min:           {stats['min']:>12.2f} {unit}")
    print(f"Max:           {stats['max']:>12.2f} {unit}")
    print(f"Mean:          {stats['mean']:>12.2f} {unit}")
    print(f"Median (p50):  {stats['median']:>12.2f} {unit}")
    print(f"Std Dev:       {stats['std']:>12.2f} {unit}")
    print(f"\nPercentiles:")
    print(f"p50:           {stats['p50']:>12.2f} {unit}")
    print(f"p90:           {stats['p90']:>12.2f} {unit}")
    print(f"p95:           {stats['p95']:>12.2f} {unit}")
    print(f"p99:           {stats['p99']:>12.2f} {unit}")
    if stats['p999'] is not None:
        print(f"p99.9:         {stats['p999']:>12.2f} {unit}")
    
    return stats


def plot_latency_histogram(df, output_file='latency_histogram.png'):
    """Create histogram of latency distribution"""
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))
    
    # Use the new column names - roundtrip latency
    latency_us = df['roundtrip_us']
    
    # Main histogram
    ax1.hist(latency_us, bins=50, edgecolor='black', alpha=0.7, color='skyblue')
    ax1.set_xlabel('Latency (μs)', fontsize=12)
    ax1.set_ylabel('Frequency', fontsize=12)
    ax1.set_title('ivshmem Latency Distribution (Round-Trip)', fontsize=14, fontweight='bold')
    ax1.grid(True, alpha=0.3)
    
    # Add statistics text
    stats_text = f"Mean: {latency_us.mean():.2f} μs\n"
    stats_text += f"Median: {latency_us.median():.2f} μs\n"
    stats_text += f"Std Dev: {latency_us.std():.2f} μs\n"
    stats_text += f"p99: {latency_us.quantile(0.99):.2f} μs"
    ax1.text(0.98, 0.97, stats_text, transform=ax1.transAxes,
             verticalalignment='top', horizontalalignment='right',
             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),
             fontsize=10, family='monospace')
    
    # Log scale histogram for better visibility of outliers
    ax2.hist(latency_us, bins=50, edgecolor='black', alpha=0.7, color='lightcoral')
    ax2.set_xlabel('Latency (μs)', fontsize=12)
    ax2.set_ylabel('Frequency (log scale)', fontsize=12)
    ax2.set_title('Latency Distribution (Log Scale)', fontsize=14, fontweight='bold')
    ax2.set_yscale('log')
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(output_file, dpi=150, bbox_inches='tight')
    print(f"\n✓ Histogram saved to {output_file}")
    
    return fig


def plot_latency_over_time(df, output_file='latency_over_time.png'):
    """Plot latency over time showing the 4-phase cache behavior analysis"""
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 12))
    
    # Overall latency over time
    ax1.plot(df['iteration'], df['roundtrip_us'], linewidth=1, alpha=0.8, color='steelblue', label='Round-trip')
    ax1.set_xlabel('Iteration', fontsize=12)
    ax1.set_ylabel('Latency (μs)', fontsize=12)
    ax1.set_title('ivshmem Round-Trip Latency Over Time', fontsize=14, fontweight='bold')
    ax1.grid(True, alpha=0.3)
    
    # Add median line
    median = df['roundtrip_us'].median()
    ax1.axhline(y=median, color='red', linestyle='--', linewidth=2, 
               label=f'Median: {median:.2f} μs', alpha=0.7)
    
    # Add p99 line
    p99 = df['roundtrip_us'].quantile(0.99)
    ax1.axhline(y=p99, color='orange', linestyle='--', linewidth=2, 
               label=f'p99: {p99:.2f} μs', alpha=0.7)
    
    ax1.legend(loc='upper right')
    
    # 4-Phase Cache Behavior Analysis (as specifically requested)
    ax2.plot(df['iteration'], df['guest_hot_cache_us'], linewidth=2, alpha=0.9, 
             label='A. Hot Cache Read (memcpy without clearing cache)', color='red', marker='o', markersize=3)
    ax2.plot(df['iteration'], df['guest_cold_cache_us'], linewidth=2, alpha=0.9, 
             label='B. Cold Cache Read (memcpy after clearing cache)', color='blue', marker='s', markersize=3)
    ax2.plot(df['iteration'], df['guest_second_pass_us'], linewidth=2, alpha=0.9, 
             label='C. Second Pass Read (second memcpy after step B)', color='orange', marker='^', markersize=3)
    ax2.plot(df['iteration'], df['guest_cached_verify_us'], linewidth=2, alpha=0.9, 
             label='D. Verify (SHA calculation after step C)', color='green', marker='d', markersize=3)
    
    ax2.set_xlabel('Iteration', fontsize=12)
    ax2.set_ylabel('Time (μs)', fontsize=12)
    ax2.set_title('4-Phase Cache Behavior Analysis', fontsize=14, fontweight='bold')
    ax2.grid(True, alpha=0.3)
    ax2.legend(loc='upper right')
    
    plt.tight_layout()
    plt.savefig(output_file, dpi=150, bbox_inches='tight')
    print(f"✓ Time series plot saved to {output_file}")
    
    return fig


def plot_percentile_chart(df, output_file='latency_percentiles.png'):
    """Create a percentile chart focused on the 4-phase cache behavior analysis"""
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))
    
    percentiles = np.arange(0, 101, 1)
    
    # Main latency percentiles
    latency_percentiles = [df['roundtrip_us'].quantile(p/100) for p in percentiles]
    
    ax1.plot(percentiles, latency_percentiles, linewidth=2, color='darkblue')
    ax1.set_xlabel('Percentile', fontsize=12)
    ax1.set_ylabel('Latency (μs)', fontsize=12)
    ax1.set_title('ivshmem Round-Trip Latency Percentile Chart', fontsize=14, fontweight='bold')
    ax1.grid(True, alpha=0.3)
    
    # Mark important percentiles
    important_p = [50, 90, 95, 99]
    for p in important_p:
        value = df['roundtrip_us'].quantile(p/100)
        ax1.plot(p, value, 'ro', markersize=8)
        ax1.annotate(f'p{p}: {value:.2f} μs', 
                   xy=(p, value), xytext=(10, 10),
                   textcoords='offset points',
                   bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.7),
                   fontsize=9)
    
    # 4-Phase Cache Behavior Percentiles (as specifically requested)
    hot_cache_percentiles = [df['guest_hot_cache_us'].quantile(p/100) for p in percentiles]
    cold_cache_percentiles = [df['guest_cold_cache_us'].quantile(p/100) for p in percentiles]
    second_pass_percentiles = [df['guest_second_pass_us'].quantile(p/100) for p in percentiles]
    cached_verify_percentiles = [df['guest_cached_verify_us'].quantile(p/100) for p in percentiles]
    
    ax2.plot(percentiles, hot_cache_percentiles, linewidth=2, 
             label='A. Hot Cache Read (memcpy without clearing cache)', color='red')
    ax2.plot(percentiles, cold_cache_percentiles, linewidth=2, 
             label='B. Cold Cache Read (memcpy after clearing cache)', color='blue')
    ax2.plot(percentiles, second_pass_percentiles, linewidth=2, 
             label='C. Second Pass Read (second memcpy after step B)', color='orange')
    ax2.plot(percentiles, cached_verify_percentiles, linewidth=2, 
             label='D. Verify (SHA calculation after step C)', color='green')
    
    ax2.set_xlabel('Percentile', fontsize=12)
    ax2.set_ylabel('Time (μs)', fontsize=12)
    ax2.set_title('4-Phase Cache Behavior Analysis Percentile Chart', fontsize=14, fontweight='bold')
    ax2.grid(True, alpha=0.3)
    ax2.legend()
    
    # Mark important percentiles for cache behavior with effect analysis
    for p in [50, 95]:
        hot_value = df['guest_hot_cache_us'].quantile(p/100)
        cold_value = df['guest_cold_cache_us'].quantile(p/100)
        second_value = df['guest_second_pass_us'].quantile(p/100)
        
        ax2.plot(p, hot_value, 'ro', markersize=6)
        ax2.plot(p, cold_value, 'bo', markersize=6)
        ax2.plot(p, second_value, 'o', color='orange', markersize=6)
        
        # Show cache effects at this percentile
        hot_to_cold = ((cold_value - hot_value) / hot_value) * 100
        cold_to_second = ((second_value - cold_value) / cold_value) * 100
        
        ax2.annotate(f'p{p}\nA→B: {hot_to_cold:+.1f}%\nB→C: {cold_to_second:+.1f}%', 
                   xy=(p, max(hot_value, cold_value, second_value)), xytext=(10, 15),
                   textcoords='offset points',
                   bbox=dict(boxstyle='round,pad=0.3', facecolor='wheat', alpha=0.8),
                   fontsize=8)
    
    plt.tight_layout()
    plt.savefig(output_file, dpi=150, bbox_inches='tight')
    print(f"✓ Percentile chart saved to {output_file}")
    
    return fig


def analyze_bandwidth_by_frame_type(bandwidth_df):
    """Analyze bandwidth results grouped by frame type"""
    if bandwidth_df is None or len(bandwidth_df) == 0:
        return None
    
    # Filter only successful transfers
    successful_df = bandwidth_df[bandwidth_df['success'] == 1]
    
    analysis = {}
    for frame_type in successful_df['frame_type'].unique():
        frame_data = successful_df[successful_df['frame_type'] == frame_type]
        if len(frame_data) > 0:
            analysis[frame_type] = {
                'count': len(frame_data),
                'total_tests': len(bandwidth_df[bandwidth_df['frame_type'] == frame_type]),
                'success_rate': len(frame_data) / len(bandwidth_df[bandwidth_df['frame_type'] == frame_type]) * 100,
                'size_mb': frame_data['size_mb'].iloc[0],
                'size_bytes': frame_data['size_bytes'].iloc[0],
                'total_bandwidth_gbps': {
                    'min': frame_data['total_mbps'].min() / 1000,  # Convert to GB/s
                    'max': frame_data['total_mbps'].max() / 1000,
                    'mean': frame_data['total_mbps'].mean() / 1000,
                    'median': frame_data['total_mbps'].median() / 1000,
                    'std': frame_data['total_mbps'].std() / 1000,
                },
                'write_bandwidth_gbps': {
                    'min': frame_data['host_memcpy_mbps'].min() / 1000,
                    'max': frame_data['host_memcpy_mbps'].max() / 1000,
                    'mean': frame_data['host_memcpy_mbps'].mean() / 1000,
                    'median': frame_data['host_memcpy_mbps'].median() / 1000,
                    'std': frame_data['host_memcpy_mbps'].std() / 1000,
                },
                'read_bandwidth_gbps': {
                    'min': frame_data['guest_memcpy_mbps'].min() / 1000,
                    'max': frame_data['guest_memcpy_mbps'].max() / 1000,
                    'mean': frame_data['guest_memcpy_mbps'].mean() / 1000,
                    'median': frame_data['guest_memcpy_mbps'].median() / 1000,
                    'std': frame_data['guest_memcpy_mbps'].std() / 1000,
                },
                'timings_ms': {
                    'host_memcpy': {
                        'min': frame_data['host_memcpy_ms'].min(),
                        'max': frame_data['host_memcpy_ms'].max(),
                        'mean': frame_data['host_memcpy_ms'].mean(),
                        'median': frame_data['host_memcpy_ms'].median(),
                        'std': frame_data['host_memcpy_ms'].std(),
                    },
                    'roundtrip': {
                        'min': frame_data['roundtrip_ms'].min(),
                        'max': frame_data['roundtrip_ms'].max(),
                        'mean': frame_data['roundtrip_ms'].mean(),
                        'median': frame_data['roundtrip_ms'].median(),
                        'std': frame_data['roundtrip_ms'].std(),
                    },
                    'guest_memcpy': {
                        'min': frame_data['guest_memcpy_ms'].min(),
                        'max': frame_data['guest_memcpy_ms'].max(),
                        'mean': frame_data['guest_memcpy_ms'].mean(),
                        'median': frame_data['guest_memcpy_ms'].median(),
                        'std': frame_data['guest_memcpy_ms'].std(),
                    },
                    'guest_verify': {
                        'min': frame_data['guest_verify_ms'].min(),
                        'max': frame_data['guest_verify_ms'].max(),
                        'mean': frame_data['guest_verify_ms'].mean(),
                        'median': frame_data['guest_verify_ms'].median(),
                        'std': frame_data['guest_verify_ms'].std(),
                    },
                    'total': {
                        'min': frame_data['total_ms'].min(),
                        'max': frame_data['total_ms'].max(),
                        'mean': frame_data['total_ms'].mean(),
                        'median': frame_data['total_ms'].median(),
                        'std': frame_data['total_ms'].std(),
                    }
                }
            }
    
    return analysis


def plot_bandwidth_analysis(bandwidth_df, output_file='bandwidth_analysis.png'):
    """Create comprehensive bandwidth analysis plots"""
    if bandwidth_df is None or len(bandwidth_df) == 0:
        print("No bandwidth data available for plotting")
        return None
    
    # Filter successful transfers
    successful_df = bandwidth_df[bandwidth_df['success'] == 1]
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    frame_types = successful_df['frame_type'].unique()
    
    # 1. Total Bandwidth by frame type (box plot)
    bandwidth_data = [successful_df[successful_df['frame_type'] == ft]['total_mbps'].values / 1000 
                     for ft in frame_types]
    
    ax1.boxplot(bandwidth_data, tick_labels=frame_types)
    ax1.set_ylabel('Total Bandwidth (GB/s)', fontsize=12)
    ax1.set_title('Total Bandwidth Distribution by Frame Type', fontsize=14, fontweight='bold')
    ax1.grid(True, alpha=0.3)
    
    # 2. Bandwidth Components Comparison
    x = np.arange(len(frame_types))
    width = 0.25
    
    write_means = [successful_df[successful_df['frame_type'] == ft]['host_memcpy_mbps'].mean() / 1000 for ft in frame_types]
    read_means = [successful_df[successful_df['frame_type'] == ft]['guest_memcpy_mbps'].mean() / 1000 for ft in frame_types]
    total_means = [successful_df[successful_df['frame_type'] == ft]['total_mbps'].mean() / 1000 for ft in frame_types]
    
    ax2.bar(x - width, write_means, width, label='Host Memcpy Bandwidth', alpha=0.8, color='green')
    ax2.bar(x, read_means, width, label='Guest Memcpy Bandwidth', alpha=0.8, color='blue')
    ax2.bar(x + width, total_means, width, label='Total Bandwidth', alpha=0.8, color='red')
    
    ax2.set_xlabel('Frame Type', fontsize=12)
    ax2.set_ylabel('Bandwidth (GB/s)', fontsize=12)
    ax2.set_title('Bandwidth Components by Frame Type', fontsize=14, fontweight='bold')
    ax2.set_xticks(x)
    ax2.set_xticklabels(frame_types)
    ax2.legend()
    ax2.grid(True, alpha=0.3, axis='y')
    
    # 3. Timing Components Breakdown
    timing_components = ['host_memcpy_ms', 'guest_memcpy_ms', 'guest_verify_ms']
    colors = ['green', 'blue', 'red']
    
    bottom = np.zeros(len(frame_types))
    for i, component in enumerate(timing_components):
        means = [successful_df[successful_df['frame_type'] == ft][component].mean() for ft in frame_types]
        ax3.bar(frame_types, means, bottom=bottom, label=component.replace('_ms', '').replace('_', ' ').replace('memcpy', 'Memcpy').title(), 
                alpha=0.8, color=colors[i])
        bottom += means
    
    ax3.set_ylabel('Time (ms)', fontsize=12)
    ax3.set_title('Timing Components Breakdown by Frame Type', fontsize=14, fontweight='bold')
    ax3.legend()
    ax3.grid(True, alpha=0.3, axis='y')
    
    # 4. Success Rate by Frame Type
    success_rates = []
    for ft in frame_types:
        total = len(bandwidth_df[bandwidth_df['frame_type'] == ft])
        successful = len(successful_df[successful_df['frame_type'] == ft])
        success_rates.append(successful / total * 100)
    
    bars = ax4.bar(frame_types, success_rates, color=['skyblue', 'lightgreen', 'lightcoral'])
    ax4.set_ylabel('Success Rate (%)', fontsize=12)
    ax4.set_title('Data Integrity Success Rate by Frame Type', fontsize=14, fontweight='bold')
    ax4.set_ylim(0, 105)
    ax4.grid(True, alpha=0.3, axis='y')
    
    # Add percentage labels on bars
    for bar, rate in zip(bars, success_rates):
        height = bar.get_height()
        ax4.text(bar.get_x() + bar.get_width()/2., height + 1,
                f'{rate:.1f}%', ha='center', va='bottom', fontweight='bold')
    
    plt.tight_layout()
    plt.savefig(output_file, dpi=150, bbox_inches='tight')
    print(f"✓ Bandwidth analysis plot saved to {output_file}")
    
    return fig


def analyze_performance_counters(perf_df):
    """Analyze performance counter data to identify bottlenecks"""
    if perf_df is None or len(perf_df) == 0:
        return None
    
    # Filter out rows with invalid data (zeros or NaN)
    valid_data = perf_df.dropna()
    
    analysis = {
        'l1_cache': {
            'host_miss_rate': {
                'mean': valid_data['host_l1_miss_rate'].mean(),
                'median': valid_data['host_l1_miss_rate'].median(),
                'std': valid_data['host_l1_miss_rate'].std(),
                'p95': valid_data['host_l1_miss_rate'].quantile(0.95),
                'max': valid_data['host_l1_miss_rate'].max(),
                'min': valid_data['host_l1_miss_rate'].min()
            },
            'guest_miss_rate': {
                'mean': valid_data['guest_l1_miss_rate'].mean(),
                'median': valid_data['guest_l1_miss_rate'].median(),
                'std': valid_data['guest_l1_miss_rate'].std(),
                'p95': valid_data['guest_l1_miss_rate'].quantile(0.95),
                'max': valid_data['guest_l1_miss_rate'].max(),
                'min': valid_data['guest_l1_miss_rate'].min()
            }
        },
        'efficiency': {
            'host_ipc': {
                'mean': valid_data['host_ipc'].mean(),
                'median': valid_data['host_ipc'].median(),
                'std': valid_data['host_ipc'].std(),
                'p95': valid_data['host_ipc'].quantile(0.95),
                'max': valid_data['host_ipc'].max(),
                'min': valid_data['host_ipc'].min()
            },
            'guest_ipc': {
                'mean': valid_data['guest_ipc'].mean(),
                'median': valid_data['guest_ipc'].median(),
                'std': valid_data['guest_ipc'].std(),
                'p95': valid_data['guest_ipc'].quantile(0.95),
                'max': valid_data['guest_ipc'].max(),
                'min': valid_data['guest_ipc'].min()
            },
            'host_cycles_per_byte': {
                'mean': valid_data['host_cycles_per_byte'].mean(),
                'median': valid_data['host_cycles_per_byte'].median(),
                'std': valid_data['host_cycles_per_byte'].std(),
                'p95': valid_data['host_cycles_per_byte'].quantile(0.95),
                'max': valid_data['host_cycles_per_byte'].max(),
                'min': valid_data['host_cycles_per_byte'].min()
            },
            'guest_cycles_per_byte': {
                'mean': valid_data['guest_cycles_per_byte'].mean(),
                'median': valid_data['guest_cycles_per_byte'].median(),
                'std': valid_data['guest_cycles_per_byte'].std(),
                'p95': valid_data['guest_cycles_per_byte'].quantile(0.95),
                'max': valid_data['guest_cycles_per_byte'].max(),
                'min': valid_data['guest_cycles_per_byte'].min()
            }
        },
        'tlb': {
            'host_tlb_misses': {
                'mean': valid_data['host_tlb_misses'].mean(),
                'median': valid_data['host_tlb_misses'].median(),
                'std': valid_data['host_tlb_misses'].std(),
                'p95': valid_data['host_tlb_misses'].quantile(0.95),
                'max': valid_data['host_tlb_misses'].max(),
                'min': valid_data['host_tlb_misses'].min()
            },
            'guest_tlb_misses': {
                'mean': valid_data['guest_tlb_misses'].mean(),
                'median': valid_data['guest_tlb_misses'].median(),
                'std': valid_data['guest_tlb_misses'].std(),
                'p95': valid_data['guest_tlb_misses'].quantile(0.95),
                'max': valid_data['guest_tlb_misses'].max(),
                'min': valid_data['guest_tlb_misses'].min()
            }
        },
        'context_switches': {
            'host': {
                'mean': valid_data['host_context_switches'].mean(),
                'median': valid_data['host_context_switches'].median(),
                'total': valid_data['host_context_switches'].sum()
            },
            'guest': {
                'mean': valid_data['guest_context_switches'].mean(),
                'median': valid_data['guest_context_switches'].median(), 
                'total': valid_data['guest_context_switches'].sum()
            }
        }
    }
    
    # Calculate performance ratios for comparison
    analysis['ratios'] = {
        'l1_miss_rate_ratio': analysis['l1_cache']['guest_miss_rate']['mean'] / analysis['l1_cache']['host_miss_rate']['mean'] if analysis['l1_cache']['host_miss_rate']['mean'] > 0 else 0,
        'ipc_ratio': analysis['efficiency']['guest_ipc']['mean'] / analysis['efficiency']['host_ipc']['mean'] if analysis['efficiency']['host_ipc']['mean'] > 0 else 0,
        'cycles_per_byte_ratio': analysis['efficiency']['guest_cycles_per_byte']['mean'] / analysis['efficiency']['host_cycles_per_byte']['mean'] if analysis['efficiency']['host_cycles_per_byte']['mean'] > 0 else 0,
        'tlb_miss_ratio': analysis['tlb']['guest_tlb_misses']['mean'] / analysis['tlb']['host_tlb_misses']['mean'] if analysis['tlb']['host_tlb_misses']['mean'] > 0 else 0
    }
    
    # Identify problematic iterations
    analysis['outliers'] = {
        'low_guest_ipc': valid_data[valid_data['guest_ipc'] < 0.1]['iteration'].tolist(),
        'high_guest_l1_miss': valid_data[valid_data['guest_l1_miss_rate'] > 1.0]['iteration'].tolist(),
        'high_cycles_per_byte': valid_data[valid_data['guest_cycles_per_byte'] > 1.0]['iteration'].tolist()
    }
    
    return analysis


def plot_performance_analysis(perf_df, output_file='performance_analysis.png'):
    """Create comprehensive performance counter analysis plots"""
    if perf_df is None or len(perf_df) == 0:
        print("No performance counter data available for plotting")
        return None
    
    fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(3, 2, figsize=(16, 18))
    
    # 1. L1 Cache Miss Rate Comparison
    ax1.plot(perf_df['iteration'], perf_df['host_l1_miss_rate'], 
             label='Host L1 Miss Rate', color='blue', alpha=0.7)
    ax1.plot(perf_df['iteration'], perf_df['guest_l1_miss_rate'], 
             label='Guest L1 Miss Rate', color='red', alpha=0.7)
    
    # Add percentile lines for host L1 miss rate
    host_l1_p50 = perf_df['host_l1_miss_rate'].quantile(0.50)
    host_l1_p90 = perf_df['host_l1_miss_rate'].quantile(0.90)
    ax1.axhline(y=host_l1_p50, color='blue', linestyle=':', linewidth=1.5, 
               label=f'Host p50: {host_l1_p50:.3f}%', alpha=0.7)
    ax1.axhline(y=host_l1_p90, color='blue', linestyle='--', linewidth=1.5, 
               label=f'Host p90: {host_l1_p90:.3f}%', alpha=0.7)
    
    # Add percentile lines for guest L1 miss rate
    guest_l1_p50 = perf_df['guest_l1_miss_rate'].quantile(0.50)
    guest_l1_p90 = perf_df['guest_l1_miss_rate'].quantile(0.90)
    ax1.axhline(y=guest_l1_p50, color='red', linestyle=':', linewidth=1.5, 
               label=f'Guest p50: {guest_l1_p50:.3f}%', alpha=0.7)
    ax1.axhline(y=guest_l1_p90, color='red', linestyle='--', linewidth=1.5, 
               label=f'Guest p90: {guest_l1_p90:.3f}%', alpha=0.7)
    
    ax1.set_xlabel('Iteration')
    ax1.set_ylabel('L1 Cache Miss Rate (%)')
    ax1.set_title('L1 Cache Miss Rate: Host vs Guest', fontweight='bold')
    ax1.legend(loc='upper right')
    ax1.grid(True, alpha=0.3)
    ax1.set_yscale('log')  # Log scale to see both ranges
    
    # 2. Instructions Per Cycle (IPC) Comparison
    ax2.plot(perf_df['iteration'], perf_df['host_ipc'], 
             label='Host IPC', color='blue', alpha=0.7)
    ax2.plot(perf_df['iteration'], perf_df['guest_ipc'], 
             label='Guest IPC', color='red', alpha=0.7)
    
    # Add percentile lines for host IPC
    host_ipc_p50 = perf_df['host_ipc'].quantile(0.50)
    host_ipc_p90 = perf_df['host_ipc'].quantile(0.90)
    ax2.axhline(y=host_ipc_p50, color='blue', linestyle=':', linewidth=1.5, 
               label=f'Host p50: {host_ipc_p50:.3f}', alpha=0.7)
    ax2.axhline(y=host_ipc_p90, color='blue', linestyle='--', linewidth=1.5, 
               label=f'Host p90: {host_ipc_p90:.2f}', alpha=0.7)
    
    # Add percentile lines for guest IPC
    guest_ipc_p50 = perf_df['guest_ipc'].quantile(0.50)
    guest_ipc_p90 = perf_df['guest_ipc'].quantile(0.90)
    ax2.axhline(y=guest_ipc_p50, color='red', linestyle=':', linewidth=1.5, 
               label=f'Guest p50: {guest_ipc_p50:.3f}', alpha=0.7)
    ax2.axhline(y=guest_ipc_p90, color='red', linestyle='--', linewidth=1.5, 
               label=f'Guest p90: {guest_ipc_p90:.2f}', alpha=0.7)
    
    ax2.set_xlabel('Iteration')
    ax2.set_ylabel('Instructions Per Cycle (IPC)')
    ax2.set_title('CPU Efficiency: Instructions Per Cycle', fontweight='bold')
    ax2.legend(loc='upper right')
    ax2.grid(True, alpha=0.3)
    
    # 3. Cycles per Byte Comparison
    ax3.plot(perf_df['iteration'], perf_df['host_cycles_per_byte'], 
             label='Host Cycles/Byte', color='blue', alpha=0.7)
    ax3.plot(perf_df['iteration'], perf_df['guest_cycles_per_byte'], 
             label='Guest Cycles/Byte', color='red', alpha=0.7)
    
    # Add percentile lines for host cycles per byte
    host_cpb_p50 = perf_df['host_cycles_per_byte'].quantile(0.50)
    host_cpb_p90 = perf_df['host_cycles_per_byte'].quantile(0.90)
    ax3.axhline(y=host_cpb_p50, color='blue', linestyle=':', linewidth=1.5, 
               label=f'Host p50: {host_cpb_p50:.3f}', alpha=0.7)
    ax3.axhline(y=host_cpb_p90, color='blue', linestyle='--', linewidth=1.5, 
               label=f'Host p90: {host_cpb_p90:.3f}', alpha=0.7)
    
    # Add percentile lines for guest cycles per byte
    guest_cpb_p50 = perf_df['guest_cycles_per_byte'].quantile(0.50)
    guest_cpb_p90 = perf_df['guest_cycles_per_byte'].quantile(0.90)
    ax3.axhline(y=guest_cpb_p50, color='red', linestyle=':', linewidth=1.5, 
               label=f'Guest p50: {guest_cpb_p50:.3f}', alpha=0.7)
    ax3.axhline(y=guest_cpb_p90, color='red', linestyle='--', linewidth=1.5, 
               label=f'Guest p90: {guest_cpb_p90:.3f}', alpha=0.7)
    
    ax3.set_xlabel('Iteration')
    ax3.set_ylabel('CPU Cycles per Byte')
    ax3.set_title('Memory Efficiency: CPU Cycles per Byte', fontweight='bold')
    ax3.legend(loc='upper right')
    ax3.grid(True, alpha=0.3)
    ax3.set_yscale('log')
    
    # 4. TLB Misses Comparison
    ax4.plot(perf_df['iteration'], perf_df['host_tlb_misses'], 
             label='Host TLB Misses', color='blue', alpha=0.7)
    ax4.plot(perf_df['iteration'], perf_df['guest_tlb_misses'], 
             label='Guest TLB Misses', color='red', alpha=0.7)
    
    # Add percentile lines for host TLB misses
    host_tlb_p50 = perf_df['host_tlb_misses'].quantile(0.50)
    host_tlb_p90 = perf_df['host_tlb_misses'].quantile(0.90)
    ax4.axhline(y=host_tlb_p50, color='blue', linestyle=':', linewidth=1.5, 
               label=f'Host p50: {host_tlb_p50:.0f}', alpha=0.7)
    ax4.axhline(y=host_tlb_p90, color='blue', linestyle='--', linewidth=1.5, 
               label=f'Host p90: {host_tlb_p90:.0f}', alpha=0.7)
    
    # Add percentile lines for guest TLB misses
    guest_tlb_p50 = perf_df['guest_tlb_misses'].quantile(0.50)
    guest_tlb_p90 = perf_df['guest_tlb_misses'].quantile(0.90)
    ax4.axhline(y=guest_tlb_p50, color='red', linestyle=':', linewidth=1.5, 
               label=f'Guest p50: {guest_tlb_p50:.0f}', alpha=0.7)
    ax4.axhline(y=guest_tlb_p90, color='red', linestyle='--', linewidth=1.5, 
               label=f'Guest p90: {guest_tlb_p90:.0f}', alpha=0.7)
    
    ax4.set_xlabel('Iteration')
    ax4.set_ylabel('TLB Misses')
    ax4.set_title('Translation Lookaside Buffer (TLB) Misses', fontweight='bold')
    ax4.legend(loc='upper right')
    ax4.grid(True, alpha=0.3)
    
    # 5. Performance Efficiency Scatter Plot
    ax5.scatter(perf_df['host_l1_miss_rate'], perf_df['host_ipc'], 
                alpha=0.6, color='blue', label='Host', s=30)
    ax5.scatter(perf_df['guest_l1_miss_rate'], perf_df['guest_ipc'], 
                alpha=0.6, color='red', label='Guest', s=30)
    ax5.set_xlabel('L1 Cache Miss Rate')
    ax5.set_ylabel('Instructions Per Cycle (IPC)')
    ax5.set_title('Performance Efficiency: Cache vs CPU', fontweight='bold')
    ax5.legend()
    ax5.grid(True, alpha=0.3)
    ax5.set_xscale('log')
    
    # 6. Context Switches Over Time
    ax6.plot(perf_df['iteration'], perf_df['host_context_switches'], 
             label='Host Context Switches', color='blue', alpha=0.7, marker='o', markersize=2)
    ax6.plot(perf_df['iteration'], perf_df['guest_context_switches'], 
             label='Guest Context Switches', color='red', alpha=0.7, marker='s', markersize=2)
    ax6.set_xlabel('Iteration')
    ax6.set_ylabel('Context Switches')
    ax6.set_title('Context Switches per Operation', fontweight='bold')
    ax6.legend()
    ax6.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(output_file, dpi=150, bbox_inches='tight')
    print(f"✓ Performance analysis plot saved to {output_file}")
    
    return fig


def plot_performance_distribution(perf_df, output_file='performance_distribution.png'):
    """Create distribution plots for key performance metrics"""
    if perf_df is None or len(perf_df) == 0:
        print("No performance counter data available for plotting")
        return None
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(14, 10))
    
    # 1. L1 Miss Rate Distribution
    ax1.hist(perf_df['host_l1_miss_rate'], bins=30, alpha=0.7, 
             label='Host', color='blue', density=True)
    ax1.hist(perf_df['guest_l1_miss_rate'], bins=30, alpha=0.7, 
             label='Guest', color='red', density=True)
    ax1.set_xlabel('L1 Cache Miss Rate')
    ax1.set_ylabel('Density')
    ax1.set_title('L1 Cache Miss Rate Distribution', fontweight='bold')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    ax1.set_xlim(0, 2)  # Focus on reasonable range
    
    # 2. IPC Distribution
    ax2.hist(perf_df['host_ipc'], bins=30, alpha=0.7, 
             label='Host', color='blue', density=True)
    ax2.hist(perf_df['guest_ipc'], bins=30, alpha=0.7, 
             label='Guest', color='red', density=True)
    ax2.set_xlabel('Instructions Per Cycle (IPC)')
    ax2.set_ylabel('Density')
    ax2.set_title('IPC Distribution', fontweight='bold')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # 3. Cycles per Byte Distribution
    ax3.hist(perf_df['host_cycles_per_byte'], bins=30, alpha=0.7, 
             label='Host', color='blue', density=True)
    ax3.hist(perf_df['guest_cycles_per_byte'], bins=30, alpha=0.7, 
             label='Guest', color='red', density=True)
    ax3.set_xlabel('CPU Cycles per Byte')
    ax3.set_ylabel('Density')
    ax3.set_title('Memory Efficiency Distribution', fontweight='bold')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    ax3.set_xlim(0, 2)  # Focus on reasonable range
    
    # 4. Box Plot Comparison
    metrics = ['host_l1_miss_rate', 'guest_l1_miss_rate', 
               'host_ipc', 'guest_ipc',
               'host_cycles_per_byte', 'guest_cycles_per_byte']
    data_to_plot = []
    labels = []
    colors = []
    
    for metric in metrics:
        if metric in perf_df.columns:
            # Filter outliers for better visualization
            q99 = perf_df[metric].quantile(0.99)
            filtered_data = perf_df[perf_df[metric] <= q99][metric]
            data_to_plot.append(filtered_data)
            labels.append(metric.replace('_', ' ').title())
            colors.append('blue' if 'host' in metric else 'red')
    
    box_plot = ax4.boxplot(data_to_plot, labels=labels, patch_artist=True)
    for patch, color in zip(box_plot['boxes'], colors):
        patch.set_facecolor(color)
        patch.set_alpha(0.7)
    
    ax4.set_ylabel('Value')  
    ax4.set_title('Performance Metrics Box Plot (99th percentile)', fontweight='bold')
    ax4.grid(True, alpha=0.3)
    ax4.tick_params(axis='x', rotation=45)
    
    plt.tight_layout()
    plt.savefig(output_file, dpi=150, bbox_inches='tight')
    print(f"✓ Performance distribution plot saved to {output_file}")
    
    return fig


def generate_report(latency_df, bandwidth_df, perf_df=None, output_file='performance_report.txt'):
    """Generate a text report with all statistics"""
    with open(output_file, 'w') as f:
        f.write("="*70 + "\n")
        f.write("IVSHMEM Performance Test Report\n")
        f.write("="*70 + "\n\n")
        
        # Latency statistics
        if latency_df is not None:
            f.write("LATENCY TEST (Round-Trip)\n")
            f.write("-"*70 + "\n")
            latency_us = latency_df['roundtrip_us']
            latency_ns = latency_df['roundtrip_ns']
            
            f.write(f"Total measurements:     {len(latency_df)}\n\n")
            
            f.write("Round-Trip Latency (nanoseconds):\n")
            f.write(f"  Min:                  {latency_ns.min():>12.0f} ns\n")
            f.write(f"  Max:                  {latency_ns.max():>12.0f} ns\n")
            f.write(f"  Mean:                 {latency_ns.mean():>12.0f} ns\n")
            f.write(f"  Median (p50):         {latency_ns.quantile(0.50):>12.0f} ns\n")
            f.write(f"  p90:                  {latency_ns.quantile(0.90):>12.0f} ns\n")
            f.write(f"  p95:                  {latency_ns.quantile(0.95):>12.0f} ns\n")
            f.write(f"  p99:                  {latency_ns.quantile(0.99):>12.0f} ns\n")
            if len(latency_df) >= 1000:
                f.write(f"  p99.9:                {latency_ns.quantile(0.999):>12.0f} ns\n")
            f.write(f"  Std Dev:              {latency_ns.std():>12.0f} ns\n\n")
            
            f.write("Round-Trip Latency (microseconds):\n")
            f.write(f"  Min:                  {latency_us.min():>12.2f} μs\n")
            f.write(f"  Max:                  {latency_us.max():>12.2f} μs\n")
            f.write(f"  Mean:                 {latency_us.mean():>12.2f} μs\n")
            f.write(f"  Median (p50):         {latency_us.quantile(0.50):>12.2f} μs\n")
            f.write(f"  p90:                  {latency_us.quantile(0.90):>12.2f} μs\n")
            f.write(f"  p95:                  {latency_us.quantile(0.95):>12.2f} μs\n")
            f.write(f"  p99:                  {latency_us.quantile(0.99):>12.2f} μs\n")
            if len(latency_df) >= 1000:
                f.write(f"  p99.9:                {latency_us.quantile(0.999):>12.2f} μs\n")
            f.write(f"  Std Dev:              {latency_us.std():>12.2f} μs\n\n")
            
            # Add detailed component breakdown
            f.write("Traditional Latency Components (microseconds):\n")
            traditional_components = {
                'Host Memcpy': 'host_memcpy_us',
                'Guest Memcpy (Legacy)': 'guest_memcpy_us', 
                'Guest Verify (Legacy)': 'guest_verify_us',
                'Notification (est)': 'notification_est_us'
            }
            
            for name, col in traditional_components.items():
                data = latency_df[col]
                f.write(f"  {name:<20} {data.mean():>8.2f} μs (p95: {data.quantile(0.95):>6.2f} μs)\n")
            
            # Add new cache behavior analysis
            f.write("\nCache Behavior Analysis (microseconds):\n")
            cache_components = {
                'Hot Cache Read': 'guest_hot_cache_us',
                'Cold Cache Read': 'guest_cold_cache_us',
                'Second Pass Read': 'guest_second_pass_us',
                'Cached Verify': 'guest_cached_verify_us'
            }
            
            for name, col in cache_components.items():
                data = latency_df[col]
                f.write(f"  {name:<20} {data.mean():>8.2f} μs (p95: {data.quantile(0.95):>6.2f} μs)\n")
            
            # Cache effects analysis
            f.write("\nCache Performance Effects:\n")
            hot_cache = latency_df['guest_hot_cache_us']
            cold_cache = latency_df['guest_cold_cache_us']
            second_pass = latency_df['guest_second_pass_us']
            cached_verify = latency_df['guest_cached_verify_us']
            legacy_verify = latency_df['guest_verify_us']
            
            hot_to_cold_effect = ((cold_cache - hot_cache) / hot_cache * 100)
            cold_to_second_effect = ((second_pass - cold_cache) / cold_cache * 100)
            overall_memory_effect = ((second_pass - hot_cache) / hot_cache * 100)
            verify_improvement = ((legacy_verify - cached_verify) / legacy_verify * 100)
            
            f.write(f"  Hot to Cold change:     {hot_to_cold_effect.mean():>8.1f}% (median: {hot_to_cold_effect.median():>6.1f}%)\n")
            f.write(f"  Cold to 2nd pass:       {cold_to_second_effect.mean():>8.1f}% (median: {cold_to_second_effect.median():>6.1f}%)\n")
            f.write(f"  Overall memory effect:  {overall_memory_effect.mean():>8.1f}% (median: {overall_memory_effect.median():>6.1f}%)\n")
            f.write(f"  SHA256 cache benefit:   {verify_improvement.mean():>8.1f}% faster (median: {verify_improvement.median():>6.1f}%)\n")
            
            f.write(f"\nMemory Access Bandwidth:\n")
            f.write(f"  Hot cache bandwidth:    {23.73 * 1000 / hot_cache.mean():>8.1f} MB/s\n")
            f.write(f"  Cold cache bandwidth:   {23.73 * 1000 / cold_cache.mean():>8.1f} MB/s\n")
            f.write(f"  Second pass bandwidth:  {23.73 * 1000 / second_pass.mean():>8.1f} MB/s\n")
            
            f.write(f"\nEstimated One-Way Latency (half of round-trip):\n")
            f.write(f"  Mean:                 {latency_ns.mean()/2:>12.0f} ns ({latency_us.mean()/2:>8.2f} μs)\n")
            f.write(f"  Median:               {latency_ns.median()/2:>12.0f} ns ({latency_us.median()/2:>8.2f} μs)\n\n")
        
        # Bandwidth statistics
        if bandwidth_df is not None and len(bandwidth_df) > 0:
            f.write("\n" + "="*70 + "\n")
            f.write("BANDWIDTH TEST\n")
            f.write("-"*70 + "\n")
            
            bandwidth_analysis = analyze_bandwidth_by_frame_type(bandwidth_df)
            
            if bandwidth_analysis:
                for frame_type, stats in bandwidth_analysis.items():
                    f.write(f"\n{frame_type.upper()} ({stats['size_mb']:.2f} MB):\n")
                    f.write(f"  Tests:                {stats['count']}/{stats['total_tests']} successful ({stats['success_rate']:.1f}%)\n")
                    f.write(f"  Total Bandwidth (GB/s):\n")
                    f.write(f"    Min:                {stats['total_bandwidth_gbps']['min']:>12.2f} GB/s\n")
                    f.write(f"    Max:                {stats['total_bandwidth_gbps']['max']:>12.2f} GB/s\n")
                    f.write(f"    Mean:               {stats['total_bandwidth_gbps']['mean']:>12.2f} GB/s\n")
                    f.write(f"    Median:             {stats['total_bandwidth_gbps']['median']:>12.2f} GB/s\n")
                    f.write(f"    Std Dev:            {stats['total_bandwidth_gbps']['std']:>12.2f} GB/s\n")
                    f.write(f"  Host Memcpy Bandwidth (GB/s):\n")
                    f.write(f"    Mean:               {stats['write_bandwidth_gbps']['mean']:>12.2f} GB/s\n")
                    f.write(f"    Median:             {stats['write_bandwidth_gbps']['median']:>12.2f} GB/s\n")
                    f.write(f"  Guest Memcpy Bandwidth (GB/s):\n")
                    f.write(f"    Mean:               {stats['read_bandwidth_gbps']['mean']:>12.2f} GB/s\n")
                    f.write(f"    Median:             {stats['read_bandwidth_gbps']['median']:>12.2f} GB/s\n")
                    f.write(f"  Timing Breakdown (ms):\n")
                    f.write(f"    Host Memcpy:        {stats['timings_ms']['host_memcpy']['mean']:>12.2f} ms\n")
                    f.write(f"    Guest Memcpy:       {stats['timings_ms']['guest_memcpy']['mean']:>12.2f} ms\n")
                    f.write(f"    Guest Verify:       {stats['timings_ms']['guest_verify']['mean']:>12.2f} ms\n")
                    f.write(f"    Total:              {stats['timings_ms']['total']['mean']:>12.2f} ms\n")
                
                # Overall bandwidth summary
                successful_df = bandwidth_df[bandwidth_df['success'] == 1]
                f.write(f"\nOVERALL BANDWIDTH SUMMARY:\n")
                f.write(f"  Total tests:          {len(bandwidth_df)}\n")
                f.write(f"  Successful:           {len(successful_df)} ({len(successful_df)/len(bandwidth_df)*100:.1f}%)\n")
                f.write(f"  Peak total bandwidth: {successful_df['total_mbps'].max() / 1000:.2f} GB/s\n")
                f.write(f"  Average total bandwidth: {successful_df['total_mbps'].mean() / 1000:.2f} GB/s\n")
                f.write(f"  Peak host memcpy bandwidth: {successful_df['host_memcpy_mbps'].max() / 1000:.2f} GB/s\n")
                f.write(f"  Peak guest memcpy bandwidth: {successful_df['guest_memcpy_mbps'].max() / 1000:.2f} GB/s\n")
                f.write(f"  Fastest host memcpy:  {successful_df['host_memcpy_ms'].min():.2f} ms\n")
                f.write(f"  Fastest total transfer: {successful_df['total_ms'].min():.2f} ms\n")
                f.write(f"  Slowest total transfer: {successful_df['total_ms'].max():.2f} ms\n")
                
                f.write(f"\nNOTES:\n")
                f.write(f"  - High bandwidth values are due to CPU cache effects\n")
                f.write(f"  - First iteration often slower due to cache warming\n")
                f.write(f"  - Actual memory bandwidth typically ~25-50 GB/s for modern systems\n")
                f.write(f"  - SHA256 verification ensures data integrity across all transfers\n")
                f.write(f"  - Host/Guest memcpy bandwidths are calculated based on individual operation times\n")
                f.write(f"  - Total bandwidth includes all operations (host memcpy + guest memcpy + verify)\n")
        
        # Performance counter analysis
        if perf_df is not None and len(perf_df) > 0:
            f.write("\n" + "="*70 + "\n")
            f.write("HARDWARE PERFORMANCE COUNTER ANALYSIS\n")
            f.write("-"*70 + "\n")
            
            perf_analysis = analyze_performance_counters(perf_df)
            if perf_analysis:
                f.write("This analysis reveals why the guest memcpy is significantly slower:\n\n")
                
                # L1 Cache Analysis
                f.write("L1 CACHE PERFORMANCE:\n")
                f.write(f"  Host L1 Miss Rate:\n")
                f.write(f"    Mean:               {perf_analysis['l1_cache']['host_miss_rate']['mean']:>12.4f}%\n")
                f.write(f"    Median:             {perf_analysis['l1_cache']['host_miss_rate']['median']:>12.4f}%\n")
                f.write(f"    95th percentile:    {perf_analysis['l1_cache']['host_miss_rate']['p95']:>12.4f}%\n")
                f.write(f"    Range:              {perf_analysis['l1_cache']['host_miss_rate']['min']:>8.4f}% - {perf_analysis['l1_cache']['host_miss_rate']['max']:>8.2f}%\n")
                
                f.write(f"  Guest L1 Miss Rate:\n")
                f.write(f"    Mean:               {perf_analysis['l1_cache']['guest_miss_rate']['mean']:>12.4f}%\n")
                f.write(f"    Median:             {perf_analysis['l1_cache']['guest_miss_rate']['median']:>12.4f}%\n")
                f.write(f"    95th percentile:    {perf_analysis['l1_cache']['guest_miss_rate']['p95']:>12.4f}%\n")
                f.write(f"    Range:              {perf_analysis['l1_cache']['guest_miss_rate']['min']:>8.4f}% - {perf_analysis['l1_cache']['guest_miss_rate']['max']:>8.2f}%\n")
                
                f.write(f"  Guest/Host L1 Miss Rate Ratio: {perf_analysis['ratios']['l1_miss_rate_ratio']:>8.2f}x\n\n")
                
                # CPU Efficiency Analysis
                f.write("CPU EFFICIENCY (Instructions Per Cycle - IPC):\n")
                f.write(f"  Host IPC:\n")
                f.write(f"    Mean:               {perf_analysis['efficiency']['host_ipc']['mean']:>12.4f}\n")
                f.write(f"    Median:             {perf_analysis['efficiency']['host_ipc']['median']:>12.4f}\n")
                f.write(f"    Range:              {perf_analysis['efficiency']['host_ipc']['min']:>8.4f} - {perf_analysis['efficiency']['host_ipc']['max']:>8.2f}\n")
                
                f.write(f"  Guest IPC:\n")
                f.write(f"    Mean:               {perf_analysis['efficiency']['guest_ipc']['mean']:>12.4f}\n")
                f.write(f"    Median:             {perf_analysis['efficiency']['guest_ipc']['median']:>12.4f}\n")
                f.write(f"    Range:              {perf_analysis['efficiency']['guest_ipc']['min']:>8.4f} - {perf_analysis['efficiency']['guest_ipc']['max']:>8.2f}\n")
                
                f.write(f"  Guest/Host IPC Ratio: {perf_analysis['ratios']['ipc_ratio']:>8.2f}x\n\n")
                
                # Memory Efficiency Analysis
                f.write("MEMORY EFFICIENCY (CPU Cycles per Byte):\n")
                f.write(f"  Host Cycles/Byte:\n")
                f.write(f"    Mean:               {perf_analysis['efficiency']['host_cycles_per_byte']['mean']:>12.4f}\n")
                f.write(f"    Median:             {perf_analysis['efficiency']['host_cycles_per_byte']['median']:>12.4f}\n")
                f.write(f"    Range:              {perf_analysis['efficiency']['host_cycles_per_byte']['min']:>8.4f} - {perf_analysis['efficiency']['host_cycles_per_byte']['max']:>8.2f}\n")
                
                f.write(f"  Guest Cycles/Byte:\n")
                f.write(f"    Mean:               {perf_analysis['efficiency']['guest_cycles_per_byte']['mean']:>12.4f}\n")
                f.write(f"    Median:             {perf_analysis['efficiency']['guest_cycles_per_byte']['median']:>12.4f}\n")
                f.write(f"    Range:              {perf_analysis['efficiency']['guest_cycles_per_byte']['min']:>8.4f} - {perf_analysis['efficiency']['guest_cycles_per_byte']['max']:>8.2f}\n")
                
                f.write(f"  Guest/Host Cycles/Byte Ratio: {perf_analysis['ratios']['cycles_per_byte_ratio']:>8.2f}x\n\n")
                
                # TLB Analysis
                f.write("TRANSLATION LOOKASIDE BUFFER (TLB) MISSES:\n")
                f.write(f"  Host TLB Misses:\n")
                f.write(f"    Mean:               {perf_analysis['tlb']['host_tlb_misses']['mean']:>12.0f}\n")
                f.write(f"    Median:             {perf_analysis['tlb']['host_tlb_misses']['median']:>12.0f}\n")
                f.write(f"    Range:              {perf_analysis['tlb']['host_tlb_misses']['min']:>8.0f} - {perf_analysis['tlb']['host_tlb_misses']['max']:>8.0f}\n")
                
                f.write(f"  Guest TLB Misses:\n")
                f.write(f"    Mean:               {perf_analysis['tlb']['guest_tlb_misses']['mean']:>12.0f}\n")
                f.write(f"    Median:             {perf_analysis['tlb']['guest_tlb_misses']['median']:>12.0f}\n")
                f.write(f"    Range:              {perf_analysis['tlb']['guest_tlb_misses']['min']:>8.0f} - {perf_analysis['tlb']['guest_tlb_misses']['max']:>8.0f}\n")
                
                f.write(f"  Guest/Host TLB Miss Ratio: {perf_analysis['ratios']['tlb_miss_ratio']:>8.2f}x\n\n")
                
                # Context Switches
                f.write("CONTEXT SWITCHES:\n")
                f.write(f"  Host:               {perf_analysis['context_switches']['host']['total']:>12.0f} total ({perf_analysis['context_switches']['host']['mean']:>6.2f} avg/op)\n")
                f.write(f"  Guest:              {perf_analysis['context_switches']['guest']['total']:>12.0f} total ({perf_analysis['context_switches']['guest']['mean']:>6.2f} avg/op)\n\n")
                
                # Problem Analysis
                f.write("PERFORMANCE BOTTLENECK ANALYSIS:\n")
                if perf_analysis['outliers']['low_guest_ipc']:
                    f.write(f"  Critical IPC Issues: {len(perf_analysis['outliers']['low_guest_ipc'])} iterations with guest IPC < 0.1\n")
                    f.write(f"    Affected iterations: {perf_analysis['outliers']['low_guest_ipc'][:10]}")
                    if len(perf_analysis['outliers']['low_guest_ipc']) > 10:
                        f.write(f" (+{len(perf_analysis['outliers']['low_guest_ipc']) - 10} more)")
                    f.write("\n")
                
                if perf_analysis['outliers']['high_guest_l1_miss']:
                    f.write(f"  High L1 Miss Rate: {len(perf_analysis['outliers']['high_guest_l1_miss'])} iterations with guest L1 miss rate > 100%\n")
                    f.write(f"    Affected iterations: {perf_analysis['outliers']['high_guest_l1_miss'][:10]}")
                    if len(perf_analysis['outliers']['high_guest_l1_miss']) > 10:
                        f.write(f" (+{len(perf_analysis['outliers']['high_guest_l1_miss']) - 10} more)")
                    f.write("\n")
                
                if perf_analysis['outliers']['high_cycles_per_byte']:
                    f.write(f"  Memory Inefficiency: {len(perf_analysis['outliers']['high_cycles_per_byte'])} iterations with guest cycles/byte > 1.0\n")
                    f.write(f"    Affected iterations: {perf_analysis['outliers']['high_cycles_per_byte'][:10]}")
                    if len(perf_analysis['outliers']['high_cycles_per_byte']) > 10:
                        f.write(f" (+{len(perf_analysis['outliers']['high_cycles_per_byte']) - 10} more)")
                    f.write("\n")
                
                f.write("\nROOT CAUSE ANALYSIS:\n")
                if perf_analysis['ratios']['ipc_ratio'] < 0.5:
                    f.write("  ⚠️  CRITICAL: Guest IPC is severely degraded - possible VM exit overhead\n")
                if perf_analysis['ratios']['l1_miss_rate_ratio'] > 2:
                    f.write("  ⚠️  Guest L1 cache performance is significantly worse than host\n")
                if perf_analysis['ratios']['tlb_miss_ratio'] > 1.5:
                    f.write("  ⚠️  Guest TLB misses indicate possible virtual memory overhead\n")
                if perf_analysis['context_switches']['guest']['mean'] > perf_analysis['context_switches']['host']['mean']:
                    f.write("  ⚠️  Guest experiences more context switches - possible scheduling issues\n")
                
                f.write("\nRECOMMENDATIONS:\n")
                f.write("  1. Investigate VM exit frequency during memory operations\n")
                f.write("  2. Consider CPU pinning and NUMA topology optimization\n")
                f.write("  3. Analyze hypervisor memory mapping efficiency\n")
                f.write("  4. Test with different memory access patterns\n")
                f.write("  5. Profile EPT (Extended Page Table) performance\n")
        
        f.write("\n" + "="*70 + "\n")
    
    print(f"✓ Performance report saved to {output_file}")


def main():
    print("="*70)
    print("IVSHMEM Performance Analysis with Cache Behavior")
    print("="*70)
    
    # Load data
    latency_df = load_latency_data()
    bandwidth_df = load_bandwidth_data()
    perf_df = load_performance_data()
    
    if latency_df is None:
        print("\nNo data to analyze. Exiting.")
        sys.exit(1)
    
    # Check if we have the new cache behavior columns
    cache_columns = ['guest_hot_cache_us', 'guest_cold_cache_us', 'guest_second_pass_us', 'guest_cached_verify_us']
    has_cache_data = all(col in latency_df.columns for col in cache_columns)
    
    if has_cache_data:
        print(f"✓ Found cache behavior analysis data with {len(latency_df)} measurements")
    else:
        print(f"⚠️  Cache behavior columns not found. Using legacy analysis only.")
        print(f"   Available columns: {list(latency_df.columns)}")
    
    # Calculate and display statistics
    print("\n" + "="*70)
    print("LATENCY ANALYSIS")
    print("="*70)
    
    calculate_statistics(latency_df['roundtrip_ns'], 'Round-Trip Latency (nanoseconds)', 'ns')
    calculate_statistics(latency_df['roundtrip_us'], 'Round-Trip Latency (microseconds)', 'μs')
    
    # Cache behavior statistics if available
    if has_cache_data:
        print("\n" + "="*70)
        print("CACHE BEHAVIOR STATISTICS")
        print("="*70)
        
        cache_stats = {
            'Hot Cache Read': 'guest_hot_cache_us',
            'Cold Cache Read': 'guest_cold_cache_us',
            'Second Pass Read': 'guest_second_pass_us',
            'Cached Verify': 'guest_cached_verify_us'
        }
        
        for name, col in cache_stats.items():
            calculate_statistics(latency_df[col], name, 'μs')
    
    # Traditional component analysis
    print("\n" + "-"*50)
    print("TRADITIONAL LATENCY COMPONENTS ANALYSIS")
    print("-"*50)
    
    traditional_components = {
        'Host Memcpy': 'host_memcpy_us',
        'Guest Memcpy (Legacy)': 'guest_memcpy_us', 
        'Guest Verify (Legacy)': 'guest_verify_us',
        'Notification (est)': 'notification_est_us'
    }
    
    for name, col in traditional_components.items():
        data = latency_df[col]
        print(f"\n{name}:")
        print(f"  Mean:    {data.mean():>12.2f} μs")
        print(f"  Median:  {data.median():>12.2f} μs")
        print(f"  p95:     {data.quantile(0.95):>12.2f} μs")
        print(f"  p99:     {data.quantile(0.99):>12.2f} μs")
    
    # New cache behavior analysis
    print("\n" + "-"*50)
    print("CACHE BEHAVIOR ANALYSIS (4-PHASE MEASUREMENT)")
    print("-"*50)
    
    cache_components = {
        'Hot Cache Read': 'guest_hot_cache_us',
        'Cold Cache Read': 'guest_cold_cache_us',
        'Second Pass Read': 'guest_second_pass_us',
        'Cached Verify': 'guest_cached_verify_us'
    }
    
    for name, col in cache_components.items():
        data = latency_df[col]
        print(f"\n{name}:")
        print(f"  Mean:    {data.mean():>12.2f} μs")
        print(f"  Median:  {data.median():>12.2f} μs")
        print(f"  p95:     {data.quantile(0.95):>12.2f} μs")
        print(f"  p99:     {data.quantile(0.99):>12.2f} μs")
    
    # Cache effect analysis
    print("\n" + "-"*50)
    print("CACHE EFFECTS ANALYSIS")
    print("-"*50)
    
    hot_cache = latency_df['guest_hot_cache_us']
    cold_cache = latency_df['guest_cold_cache_us']
    second_pass = latency_df['guest_second_pass_us']
    cached_verify = latency_df['guest_cached_verify_us']
    
    # Calculate cache effects
    hot_to_cold_effect = ((cold_cache - hot_cache) / hot_cache * 100)
    cold_to_second_effect = ((second_pass - cold_cache) / cold_cache * 100)
    overall_memory_effect = ((second_pass - hot_cache) / hot_cache * 100)
    
    print(f"\nCache Performance Effects:")
    print(f"  Hot to Cold change:     {hot_to_cold_effect.mean():>8.1f}% (median: {hot_to_cold_effect.median():>6.1f}%)")
    print(f"  Cold to 2nd pass:       {cold_to_second_effect.mean():>8.1f}% (median: {cold_to_second_effect.median():>6.1f}%)")
    print(f"  Overall memory effect:  {overall_memory_effect.mean():>8.1f}% (median: {overall_memory_effect.median():>6.1f}%)")
    
    print(f"\nMemory Access Patterns:")
    print(f"  Hot cache bandwidth:    {23.73 * 1000 / hot_cache.mean():>8.1f} MB/s")
    print(f"  Cold cache bandwidth:   {23.73 * 1000 / cold_cache.mean():>8.1f} MB/s")
    print(f"  Second pass bandwidth:  {23.73 * 1000 / second_pass.mean():>8.1f} MB/s")
    
    # Verify performance comparison
    legacy_verify = latency_df['guest_verify_us']
    cached_verify = latency_df['guest_cached_verify_us']
    verify_improvement = ((legacy_verify - cached_verify) / legacy_verify * 100)
    
    print(f"\nSHA256 Verification Performance:")
    print(f"  Legacy verify:          {legacy_verify.mean():>8.2f} μs (on uncached data)")
    print(f"  Cached verify:          {cached_verify.mean():>8.2f} μs (on cached data)")
    print(f"  Cache benefit:          {verify_improvement.mean():>8.1f}% faster (median: {verify_improvement.median():>6.1f}%)")
    
    print(f"\nEstimated One-Way Latency:")
    print(f"  Mean:    {latency_df['roundtrip_ns'].mean()/2:>12.0f} ns ({latency_df['roundtrip_us'].mean()/2:>8.2f} μs)")
    print(f"  Median:  {latency_df['roundtrip_ns'].median()/2:>12.0f} ns ({latency_df['roundtrip_us'].median()/2:>8.2f} μs)")
    
    # Performance counter analysis
    if perf_df is not None and len(perf_df) > 0:
        print("\n" + "="*70)
        print("HARDWARE PERFORMANCE COUNTER ANALYSIS")
        print("="*70)
        
        perf_analysis = analyze_performance_counters(perf_df)
        if perf_analysis:
            print(f"\nL1 CACHE MISS RATES:")
            print(f"  Host:    {perf_analysis['l1_cache']['host_miss_rate']['mean']:>8.4f}% (median: {perf_analysis['l1_cache']['host_miss_rate']['median']:>6.4f}%)")
            print(f"  Guest:   {perf_analysis['l1_cache']['guest_miss_rate']['mean']:>8.4f}% (median: {perf_analysis['l1_cache']['guest_miss_rate']['median']:>6.4f}%)")
            print(f"  Ratio:   {perf_analysis['ratios']['l1_miss_rate_ratio']:>8.2f}x (guest/host)")
            
            print(f"\nCPU EFFICIENCY (IPC - Instructions Per Cycle):")
            print(f"  Host:    {perf_analysis['efficiency']['host_ipc']['mean']:>8.4f} (median: {perf_analysis['efficiency']['host_ipc']['median']:>6.4f})")
            print(f"  Guest:   {perf_analysis['efficiency']['guest_ipc']['mean']:>8.4f} (median: {perf_analysis['efficiency']['guest_ipc']['median']:>6.4f})")
            print(f"  Ratio:   {perf_analysis['ratios']['ipc_ratio']:>8.2f}x (guest/host)")
            
            print(f"\nMEMORY EFFICIENCY (CPU Cycles per Byte):")
            print(f"  Host:    {perf_analysis['efficiency']['host_cycles_per_byte']['mean']:>8.4f} (median: {perf_analysis['efficiency']['host_cycles_per_byte']['median']:>6.4f})")
            print(f"  Guest:   {perf_analysis['efficiency']['guest_cycles_per_byte']['mean']:>8.4f} (median: {perf_analysis['efficiency']['guest_cycles_per_byte']['median']:>6.4f})")
            print(f"  Ratio:   {perf_analysis['ratios']['cycles_per_byte_ratio']:>8.2f}x (guest/host)")
            
            print(f"\nTLB MISSES:")
            print(f"  Host:    {perf_analysis['tlb']['host_tlb_misses']['mean']:>8.0f} (median: {perf_analysis['tlb']['host_tlb_misses']['median']:>6.0f})")
            print(f"  Guest:   {perf_analysis['tlb']['guest_tlb_misses']['mean']:>8.0f} (median: {perf_analysis['tlb']['guest_tlb_misses']['median']:>6.0f})")
            print(f"  Ratio:   {perf_analysis['ratios']['tlb_miss_ratio']:>8.2f}x (guest/host)")
            
            print(f"\nCONTEXT SWITCHES:")
            print(f"  Host:    {perf_analysis['context_switches']['host']['total']:>8.0f} total ({perf_analysis['context_switches']['host']['mean']:>6.2f} avg/op)")
            print(f"  Guest:   {perf_analysis['context_switches']['guest']['total']:>8.0f} total ({perf_analysis['context_switches']['guest']['mean']:>6.2f} avg/op)")
            
            # Highlight critical issues
            critical_issues = []
            if perf_analysis['ratios']['ipc_ratio'] < 0.5:
                critical_issues.append("Severe Guest IPC degradation")
            if perf_analysis['ratios']['l1_miss_rate_ratio'] > 2:
                critical_issues.append("Poor Guest L1 cache performance")
            if perf_analysis['ratios']['tlb_miss_ratio'] > 1.5:
                critical_issues.append("High Guest TLB miss rate")
            
            if critical_issues:
                print(f"\n⚠️  CRITICAL PERFORMANCE ISSUES DETECTED:")
                for issue in critical_issues:
                    print(f"    - {issue}")
            
            if perf_analysis['outliers']['low_guest_ipc']:
                print(f"\n📊 PROBLEMATIC ITERATIONS:")
                print(f"    {len(perf_analysis['outliers']['low_guest_ipc'])} iterations with guest IPC < 0.1")
                print(f"    Examples: {perf_analysis['outliers']['low_guest_ipc'][:5]}")
    
    # Bandwidth analysis
    if bandwidth_df is not None and len(bandwidth_df) > 0:
        print("\n" + "="*70)
        print("BANDWIDTH ANALYSIS")
        print("="*70)
        
        bandwidth_analysis = analyze_bandwidth_by_frame_type(bandwidth_df)
        if bandwidth_analysis:
            for frame_type, stats in bandwidth_analysis.items():
                print(f"\n{frame_type.upper()} ({stats['size_mb']:.2f} MB):")
                print(f"  Success Rate:         {stats['success_rate']:>8.1f}% ({stats['count']}/{stats['total_tests']})")
                print(f"  Total Bandwidth (GB/s): {stats['total_bandwidth_gbps']['mean']:>8.2f} ± {stats['total_bandwidth_gbps']['std']:>6.2f}")
                print(f"    Range:              {stats['total_bandwidth_gbps']['min']:>8.2f} - {stats['total_bandwidth_gbps']['max']:>8.2f}")
                print(f"  Write Bandwidth (GB/s): {stats['write_bandwidth_gbps']['mean']:>8.2f} ± {stats['write_bandwidth_gbps']['std']:>6.2f}")
                print(f"  Memcpy Bandwidth (GB/s): {stats['read_bandwidth_gbps']['mean']:>8.2f} ± {stats['read_bandwidth_gbps']['std']:>6.2f}")
                print(f"  Timing Breakdown (ms):")
                print(f"    Host Memcpy:        {stats['timings_ms']['host_memcpy']['mean']:>8.2f} ± {stats['timings_ms']['host_memcpy']['std']:>6.2f}")
                print(f"    Guest Memcpy:       {stats['timings_ms']['guest_memcpy']['mean']:>8.2f} ± {stats['timings_ms']['guest_memcpy']['std']:>6.2f}")
                print(f"    Guest Verify:       {stats['timings_ms']['guest_verify']['mean']:>8.2f} ± {stats['timings_ms']['guest_verify']['std']:>6.2f}")
                print(f"    Total:              {stats['timings_ms']['total']['mean']:>8.2f} ± {stats['timings_ms']['total']['std']:>6.2f}")
            
            # Overall summary
            successful_df = bandwidth_df[bandwidth_df['success'] == 1]
            print(f"\nOVERALL BANDWIDTH SUMMARY:")
            print(f"  Total tests:          {len(bandwidth_df)}")
            print(f"  Successful:           {len(successful_df)} ({len(successful_df)/len(bandwidth_df)*100:.1f}%)")
            print(f"  Peak total bandwidth: {successful_df['total_mbps'].max() / 1000:.2f} GB/s")
            print(f"  Average total bandwidth: {successful_df['total_mbps'].mean() / 1000:.2f} GB/s")
            print(f"  Peak host memcpy bandwidth: {successful_df['host_memcpy_mbps'].max() / 1000:.2f} GB/s")
            print(f"  Peak guest memcpy bandwidth: {successful_df['guest_memcpy_mbps'].max() / 1000:.2f} GB/s")
            print(f"  Fastest host memcpy:  {successful_df['host_memcpy_ms'].min():.2f} ms")
            print(f"  Fastest total:        {successful_df['total_ms'].min():.2f} ms")
    
    # Generate plots
    print("\n" + "="*70)
    print("GENERATING PLOTS")
    print("="*70)
    
    plot_latency_histogram(latency_df)
    plot_latency_over_time(latency_df)
    plot_percentile_chart(latency_df)
    
    if bandwidth_df is not None and len(bandwidth_df) > 0:
        plot_bandwidth_analysis(bandwidth_df)
    
    if perf_df is not None and len(perf_df) > 0:
        plot_performance_analysis(perf_df)
        plot_performance_distribution(perf_df)
    
    # Generate report
    print("\n" + "="*70)
    print("GENERATING REPORT")
    print("="*70)
    generate_report(latency_df, bandwidth_df, perf_df)
    
    print("\n" + "="*70)
    print("Analysis complete!")
    print("="*70)
    print("\nGenerated files:")
    print("  - latency_histogram.png")
    print("  - latency_over_time.png (with cache behavior analysis)")
    print("  - latency_percentiles.png (with cache behavior percentiles)")
    if bandwidth_df is not None and len(bandwidth_df) > 0:
        print("  - bandwidth_analysis.png")
    if perf_df is not None and len(perf_df) > 0:
        print("  - performance_analysis.png")
        print("  - performance_distribution.png")
    print("  - performance_report.txt (with cache behavior insights)")
    
    # Show key cache behavior insights
    if has_cache_data:
        hot_cache = latency_df['guest_hot_cache_us']
        cold_cache = latency_df['guest_cold_cache_us']
        cache_effect = ((cold_cache - hot_cache) / hot_cache * 100).mean()
        print(f"\n🔍 KEY CACHE INSIGHTS:")
        print(f"   Cache effect: {cache_effect:+.1f}% (cold vs hot)")
        print(f"   Hot cache: {hot_cache.mean():.1f} μs ({23.73*1000/hot_cache.mean():.0f} MB/s)")
        print(f"   Cold cache: {cold_cache.mean():.1f} μs ({23.73*1000/cold_cache.mean():.0f} MB/s)")


if __name__ == '__main__':
    main()

